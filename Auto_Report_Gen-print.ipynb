{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00ea7485-4c94-496d-ac0a-be4e47622185",
   "metadata": {},
   "source": [
    "## Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e00d1c-bec9-4f0a-a5b8-c932bcd4088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd  # For data manipulation\n",
    "import numpy as np  # For numerical operations\n",
    "import warnings  # To handle warnings\n",
    "import sys  # For system-related functions\n",
    "import os  # For operating system tasks\n",
    "import platform  # For platform information\n",
    "import time  # For time-related functions\n",
    "from colorama import Fore  # For colored text in the terminal\n",
    "from openpyxl import Workbook  # For working with Excel files\n",
    "from openpyxl.utils import get_column_letter  # To convert column numbers to letters\n",
    "from openpyxl.styles import Border, Side, Font, Alignment, PatternFill  # For styling Excel cells\n",
    "from datetime import datetime  # For date and time handling\n",
    "\n",
    "# Ignore warnings to keep output clean\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf53441-963c-4162-bb9a-68fea661b1a9",
   "metadata": {},
   "source": [
    "## Deploy Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0b9e47-c702-49b8-bb6a-62a92a341271",
   "metadata": {},
   "source": [
    "### Clear console function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbba6a1d-edaf-455c-9e2e-4eab4ddbb10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_console():\n",
    "    \"\"\"\n",
    "    Clear the console screen.\n",
    "\n",
    "    This function checks the operating system and executes the appropriate command\n",
    "    to clear the console. It uses 'cls' for Windows and 'clear' for Unix/Linux/Mac.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if platform.system() == \"Windows\":\n",
    "        os.system('cls')  # For Windows\n",
    "    else:\n",
    "        os.system('clear')  # For Unix/Linux/Mac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40490daf-a0d4-41fc-8609-7c3c3190b522",
   "metadata": {},
   "source": [
    "### Display intro banner function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b35a4b9-34a9-4eba-8700-87718d62578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_banner():\n",
    "    \"\"\"\n",
    "    Display a decorative banner in the console.\n",
    "\n",
    "    This function prints a stylized banner that includes information about the \n",
    "    Auto Correlation and Cpk Report Generator, along with the author's name, \n",
    "    email, and GitHub link. The banner is displayed in cyan color and is followed \n",
    "    by a brief pause.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    banner = '''\n",
    "┏┓       ┏┓        ┓   •           ┓  ┏┓  ┓   ┳┓           ┏┓               \n",
    "┣┫┓┏╋┏┓  ┃ ┏┓┏┓┏┓┏┓┃┏┓╋┓┏┓┏┓  ┏┓┏┓┏┫  ┃ ┏┓┃┏  ┣┫┏┓┏┓┏┓┏┓╋  ┃┓┏┓┏┓┏┓┏┓┏┓╋┏┓┏┓\n",
    "┛┗┗┻┗┗┛  ┗┛┗┛┛ ┛ ┗ ┗┗┻┗┗┗┛┛┗  ┗┻┛┗┗┻  ┗┛┣┛┛┗  ┛┗┗ ┣┛┗┛┛ ┗  ┗┛┗ ┛┗┗ ┛ ┗┻┗┗┛┛ \n",
    "                                        ┛         ┛                                                                                                              \n",
    "Auto Correlation and Cpk Report Generator\n",
    "Coded by Mohamad Haikal bin Mohamad Nazari\n",
    "Email: mohamadhaikal.mohamadnazari@tessolve.com\n",
    "Github: https://github.com/haikal5e\n",
    "    '''\n",
    "    print(f\"{Fore.CYAN}{banner}{Fore.RESET}\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0590dec-5d4b-4007-8f4b-445d7ae5e0bf",
   "metadata": {},
   "source": [
    "### Display thank you function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418777de-f5d7-432b-a7a9-de1c578dd4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thank_you():\n",
    "    \"\"\"\n",
    "    Display a thank you message in the console.\n",
    "\n",
    "    This function prints a stylized thank you message in green color. The message \n",
    "    is displayed in a decorative format and is followed by a brief pause.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    thank = '''\n",
    "┏┳┓┓     ┓   ┓┏    \n",
    " ┃ ┣┓┏┓┏┓┃┏  ┗┫┏┓┓┏\n",
    " ┻ ┛┗┗┻┛┗┛┗  ┗┛┗┛┗┻\n",
    "                                                                                                              \n",
    "    '''\n",
    "    \n",
    "    print(f\"{Fore.GREEN}{thank}{Fore.RESET}\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b03215c-a6f5-4f0d-8d6a-9177d775724a",
   "metadata": {},
   "source": [
    "### Get product information function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c91f77-bb21-4339-8c7f-d095305b9e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_information():\n",
    "    \"\"\"\n",
    "    Collect and manage product information with user verification.\n",
    "\n",
    "    This function prompts the user to enter various product details, including \n",
    "    the test card name, part name, package, lead count, and description. It \n",
    "    ensures that the user cannot leave any fields empty and allows for \n",
    "    reviewing and modifying the entered information before final confirmation.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the collected product information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize product information dictionary\n",
    "    product_info = {\n",
    "        'Test Card Name': '',\n",
    "        'Part Name': '',\n",
    "        'Package': '',\n",
    "        'Lead Count': '',\n",
    "        'Description': ''\n",
    "    }\n",
    "    \n",
    "    # Collect initial product information\n",
    "    print(\"Please enter the following product information:\")\n",
    "    \n",
    "    for key in product_info.keys():\n",
    "        while True:\n",
    "            value = input(f\"Enter {key}: \").strip()\n",
    "            if value:\n",
    "                product_info[key] = value\n",
    "                break\n",
    "            else:\n",
    "                print()\n",
    "                print(f\"{key} cannot be empty. Please try again.\")\n",
    "\n",
    "    print()  # Retained for separation\n",
    "    \n",
    "    # Review and confirmation loop\n",
    "    while True:\n",
    "        clear_console()\n",
    "        print(\"Current Product Information:\")\n",
    "        for key, value in product_info.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        \n",
    "        # Confirmation and change option\n",
    "        confirm = input(\"\\nAre you satisfied with the current information? (yes/no): \").strip().lower()\n",
    "        \n",
    "        if confirm == 'yes':\n",
    "            print()  # Retained for separation\n",
    "            break\n",
    "        elif confirm == 'no':\n",
    "            print()  # Retained for separation\n",
    "            # Allow specific field changes\n",
    "            while True:\n",
    "                clear_console()\n",
    "                print(\"Current Product Information:\")\n",
    "                for key, value in product_info.items():\n",
    "                    print(f\"{key}: {value}\")\n",
    "                print()  # Retained for separation\n",
    "                \n",
    "                # Field selection for modification\n",
    "                print(\"Which field would you like to change?\")\n",
    "                for i, key in enumerate(product_info.keys(), 1):\n",
    "                    print(f\"{i}. {key}\")\n",
    "                print(\"0. Go back to confirmation\")\n",
    "                print()  # Retained for separation\n",
    "                \n",
    "                try:\n",
    "                    choice = int(input(\"Enter the number of the field you want to modify: \"))\n",
    "                    \n",
    "                    # print()  # Retained for separation\n",
    "                    \n",
    "                    if choice == 0:\n",
    "                        break\n",
    "                    elif 1 <= choice <= len(product_info):\n",
    "                        field = list(product_info.keys())[choice - 1]\n",
    "                        print()  # Retained for separation\n",
    "                        new_value = input(f\"Enter new {field}: \").strip()\n",
    "                        \n",
    "                        # Validate input\n",
    "                        if new_value:\n",
    "                            product_info[field] = new_value\n",
    "                            print()  # Retained for separation\n",
    "                            print(f\"{field} updated successfully!\")\n",
    "                        else:\n",
    "                            print()  # Retained for separation\n",
    "                            print(\"Invalid input. Field cannot be empty.\")\n",
    "                        \n",
    "                        input(\"\\nPress Enter to continue...\\n\")\n",
    "                    else:\n",
    "                        print()  # Retained for separation\n",
    "                        print(\"Invalid choice. Please try again.\")\n",
    "                        input(\"\\nPress Enter to continue...\\n\")\n",
    "                \n",
    "                except ValueError:\n",
    "                    print()  # Retained for separation\n",
    "                    print(\"Please enter a valid number.\")\n",
    "                    input(\"\\nPress Enter to continue...\\n\")\n",
    "        else:\n",
    "            print()  # Retained for separation\n",
    "            print(\"Invalid input. Please enter 'yes' or 'no'.\")\n",
    "            input(\"\\nPress Enter to continue...\\n\")\n",
    "    \n",
    "    return product_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437700b2-9101-4b09-838a-f0353e013d48",
   "metadata": {},
   "source": [
    "### Get setup information function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d39b3be-0791-416c-b87b-c4a292dce37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_setup_information():\n",
    "    \"\"\"\n",
    "    Collect and manage setup information with user verification.\n",
    "\n",
    "    This function prompts the user to enter various setup details, including \n",
    "    the tester ID, reference board, new board ID, and test program. It ensures \n",
    "    that the user cannot leave any fields empty and allows for reviewing and \n",
    "    modifying the entered information before final confirmation.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the collected setup information.\n",
    "    \"\"\"\n",
    "    clear_console()\n",
    "    \n",
    "    # Initialize setup information dictionary\n",
    "    setup_info = {\n",
    "        'Tester ID': '',\n",
    "        'Reference Board': '',\n",
    "        'New Board ID': '',\n",
    "        'Test Program': ''\n",
    "    }\n",
    "    \n",
    "    # Collect initial setup information\n",
    "    print(\"Please enter the following setup information:\")\n",
    "    \n",
    "    for key in setup_info.keys():\n",
    "        while True:\n",
    "            value = input(f\"Enter {key}: \").strip()\n",
    "            if value:\n",
    "                setup_info[key] = value\n",
    "                break\n",
    "            else:\n",
    "                print()\n",
    "                print(f\"{key} cannot be empty. Please try again.\")\n",
    "\n",
    "    print()  # Retained for separation\n",
    "    \n",
    "    # Review and confirmation loop\n",
    "    while True:\n",
    "        clear_console()\n",
    "        print(\"Current Setup Information:\")\n",
    "        for key, value in setup_info.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        \n",
    "        # Confirmation and change option\n",
    "        confirm = input(\"\\nAre you satisfied with the current setup information? (yes/no): \").strip().lower()\n",
    "        \n",
    "        if confirm == 'yes':\n",
    "            print()  # Retained for separation\n",
    "            break\n",
    "        elif confirm == 'no':\n",
    "            print()  # Retained for separation\n",
    "            # Allow specific field changes\n",
    "            while True:\n",
    "                clear_console()\n",
    "                print(\"Current Setup Information:\")\n",
    "                for key, value in setup_info.items():\n",
    "                    print(f\"{key}: {value}\")\n",
    "                print()  # Retained for separation\n",
    "                \n",
    "                # Field selection for modification\n",
    "                print(\"Which field would you like to change?\")\n",
    "                for i, key in enumerate(setup_info.keys(), 1):\n",
    "                    print(f\"{i}. {key}\")\n",
    "                print(\"0. Go back to confirmation\")\n",
    "                print()  # Retained for separation\n",
    "                \n",
    "                try:\n",
    "                    choice = int(input(\"Enter the number of the field you want to modify: \"))\n",
    "                    \n",
    "                    if choice == 0:\n",
    "                        break\n",
    "                    elif 1 <= choice <= len(setup_info):\n",
    "                        print()  # Retained for separation\n",
    "                        field = list(setup_info.keys())[choice - 1]\n",
    "                        new_value = input(f\"Enter new {field}: \").strip()\n",
    "                        \n",
    "                        # Validate input\n",
    "                        if new_value:\n",
    "                            setup_info[field] = new_value\n",
    "                            print()\n",
    "                            print(f\"{field} updated successfully!\")\n",
    "                        else:\n",
    "                            print(\"\\nInvalid input. Field cannot be empty.\")\n",
    "                        \n",
    "                        input(\"\\nPress Enter to continue...\\n\")\n",
    "                    else:\n",
    "                        print(\"\\nInvalid choice. Please try again.\")\n",
    "                        input(\"\\nPress Enter to continue...\\n\")\n",
    "                \n",
    "                except ValueError:\n",
    "                    print(\"\\nPlease enter a valid number.\")\n",
    "                    input(\"\\nPress Enter to continue...\\n\")\n",
    "        else:\n",
    "            print(\"\\nInvalid input. Please enter 'yes' or 'no'.\")\n",
    "            input(\"\\nPress Enter to continue...\\n\")\n",
    "    \n",
    "    return setup_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab8af1f-ab41-40e0-8dad-50a23c0e8a8d",
   "metadata": {},
   "source": [
    "### Get data for New Boards (NB), Reference Boards (RB) and Limit file function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f796cf66-985a-4986-9217-06784573e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"\n",
    "    Gets input from the user about boards, units, and RB units, and returns file path lists.\n",
    "\n",
    "    This function prompts the user to enter the number of new boards and units tested, \n",
    "    ensuring the values are between 1 and 9. It collects file paths for each board and \n",
    "    unit, as well as a limit file path, and allows the user to review and modify the \n",
    "    entered paths before final confirmation.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - list: A list of lists with file paths for each board and unit.\n",
    "            - list: A list of file paths for RB units.\n",
    "            - int: The number of boards.\n",
    "            - int: The number of units.\n",
    "            - str: The file path for the limit file.\n",
    "    \"\"\"\n",
    "    \n",
    "    clear_console()  # Clear console at the start of the function\n",
    "    \n",
    "    while True:        \n",
    "        try:\n",
    "            num_boards = int(input(\"Enter the number of New Boards (NB) (between 1 and 9): \"))\n",
    "            if 1 <= num_boards <= 9:  # Check if the number is between 1 and 9\n",
    "                break\n",
    "            else:\n",
    "                clear_console()\n",
    "                print(\"Please enter a number between 1 and 9!\")\n",
    "                sys.stdout.flush()                \n",
    "        except ValueError:\n",
    "            clear_console()\n",
    "            print(\"Invalid input. Please enter a valid number!\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            num_units = int(input(\"Enter the number of units tested (between 1 and 9): \"))\n",
    "            if 1 <= num_units <= 9:  # Check if the number is between 1 and 9\n",
    "                break\n",
    "            else:\n",
    "                print(\"Please enter a number between 1 and 9!\")\n",
    "                sys.stdout.flush()\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid number!\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    # Confirmation step\n",
    "    while True:\n",
    "        clear_console()\n",
    "        confirmation = input(f\"You entered {num_boards} boards and {num_units} units. Are you sure these amounts are correct? (yes/no): \").strip().lower()\n",
    "        if confirmation == 'yes':\n",
    "            break\n",
    "        elif confirmation == 'no':\n",
    "            clear_console()\n",
    "            print(\"Let's enter the amounts again.\")\n",
    "            time.sleep(1.5)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            # Reset the input for number of boards and units\n",
    "            while True:\n",
    "                clear_console()\n",
    "                try:\n",
    "                    num_boards = int(input(\"Enter the number of New Boards (NB) (between 1 and 9): \"))\n",
    "                    if 1 <= num_boards <= 9:  # Check if the number is between 1 and 9\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"Please enter a number between 1 and 9!\")\n",
    "                        sys.stdout.flush()\n",
    "                except ValueError:\n",
    "                    print(\"Invalid input. Please enter a valid number!\")\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    num_units = int(input(\"Enter the number of units tested (between 1 and 9): \"))\n",
    "                    if 1 <= num_units <= 9:  # Check if the number is between 1 and 9\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"Please enter a number between 1 and 9!\")\n",
    "                        sys.stdout.flush()\n",
    "                except ValueError:\n",
    "                    print(\"Invalid input. Please enter a valid number!\")\n",
    "                    sys.stdout.flush()\n",
    "            continue  # Go back to the confirmation step after resetting the values\n",
    "        else:\n",
    "            clear_console()\n",
    "            print(\"Invalid input. Please enter 'yes' or 'no'.\")\n",
    "            time.sleep(1.5)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    print()  # Necessary for spacing\n",
    "\n",
    "    board_file_paths = []\n",
    "    for board_num in range(num_boards):  # Range starts from 0\n",
    "        board_paths = []\n",
    "        for unit_num in range(num_units):  # Range starts from 0\n",
    "            while True:\n",
    "                file_path = input(f\"Enter the file path for NB{board_num + 1} U{unit_num + 1} (CSV file): \")\n",
    "                if file_path.lower().endswith(\".csv\"):\n",
    "                    board_paths.append(file_path)\n",
    "                    break\n",
    "                else:\n",
    "                    print() # Retained for separation\n",
    "                    print(\"Invalid input. Please enter a file path that ends with '.csv'.\")\n",
    "                    sys.stdout.flush()\n",
    "        print() # Retained for separation\n",
    "        board_file_paths.append(board_paths)\n",
    "\n",
    "    print()  # Necessary for spacing\n",
    "\n",
    "    rb_file_paths = []\n",
    "    for unit_num in range(num_units):  # Range starts from 0\n",
    "        while True:\n",
    "            file_path = input(f\"Enter the file path for RB U{unit_num + 1} (CSV file): \")\n",
    "            if file_path.lower().endswith (\".csv\"):\n",
    "                rb_file_paths.append(file_path)\n",
    "                break\n",
    "            else:\n",
    "                print() # Retained for separation\n",
    "                print(\"Invalid input. Please enter a file path that ends with '.csv'.\")\n",
    "                sys.stdout.flush()\n",
    "    \n",
    "    print()  # Necessary for spacing\n",
    "    \n",
    "    while True:\n",
    "        limit_file = input(\"Enter the file path for the limit file (CSV file): \")\n",
    "        if limit_file.lower().endswith(\".csv\"):\n",
    "            break\n",
    "        else:\n",
    "            print() # Retained for separation\n",
    "            print(\"Invalid input. Please enter a file path that ends with '.csv'.\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    # Review and change file paths\n",
    "    while True:\n",
    "        clear_console()\n",
    "        print(\"Current file paths:\\n\")\n",
    "        for i, board_paths in enumerate(board_file_paths):\n",
    "            for j, path in enumerate(board_paths):\n",
    "                print(f\"NB{(i + 1)} U{(j + 1)}: {path}\")\n",
    "        \n",
    "        for j, path in enumerate(rb_file_paths):\n",
    "            print(f\"RB U{(j + 1)}: {path}\")\n",
    "\n",
    "        print(f\"Limit file: {limit_file}\")\n",
    "\n",
    "        change = input(\"\\nAre you satisfied with current file paths? (yes/no): \").strip().lower()\n",
    "        if change == 'yes':\n",
    "            break\n",
    "        elif change == 'no':\n",
    "            print() # Retained for separation\n",
    "            while True:\n",
    "                path_type = input(\"Which path do you want to change? (NB/RB/Limit): \").strip().lower()\n",
    "                if path_type == 'nb':\n",
    "                    print() # Retained for separation\n",
    "                    # Validate board number\n",
    "                    while True:\n",
    "                        try:\n",
    "                            board_index = int(input(f\"Enter the new board number (1 to {num_boards}): \")) - 1\n",
    "                            if 0 <= board_index < num_boards:\n",
    "                                break\n",
    "                            else:\n",
    "                                print() # Retained for separation\n",
    "                                print(\"Input out of range! Please enter a valid board number.\")\n",
    "                                sys.stdout.flush()\n",
    "                        except ValueError:\n",
    "                            print() # Retained for separation\n",
    "                            print(\"Invalid input. Please enter a number.\")\n",
    "                            sys.stdout.flush()\n",
    "                    \n",
    "                    print() # Retained for separation\n",
    "                    # Validate unit number\n",
    "                    while True:\n",
    "                        try:\n",
    "                            unit_index = int(input(f\"Enter the unit number (1 to {num_units}): \")) - 1\n",
    "                            if 0 <= unit_index < num_units:\n",
    "                                break\n",
    "                            else:\n",
    "                                print() # Retained for separation\n",
    "                                print(\"Input out of range! Please enter a valid unit number.\")\n",
    "                                sys.stdout.flush()\n",
    "                        except ValueError:\n",
    "                            print() # Retained for separation\n",
    "                            print(\"Invalid input. Please enter a number.\")\n",
    "                            sys.stdout.flush()\n",
    "                    \n",
    "                    print() # Retained for separation\n",
    "                    # Get new file path\n",
    "                    while True:\n",
    "                        new_path = input(f\"Enter the new file path for NB{board_index + 1} U{unit_index + 1} (CSV file): \")\n",
    "                        if new_path.lower().endswith(\".csv\"):\n",
    "                            board_file_paths[board_index][unit_index] = new_path\n",
    "                            break\n",
    "                        else:\n",
    "                            print() # Retained for separation\n",
    "                            print(\"Invalid path. It must end with '.csv'.\")\n",
    "                            sys.stdout.flush()\n",
    "\n",
    "                elif path_type == 'rb':\n",
    "                    print() # Retained for separation\n",
    "                    # Validate unit number for RB\n",
    "                    while True:\n",
    "                        try:\n",
    "                            unit_index = int(input(f\"Enter the unit number (1 to {num_units}): \")) - 1\n",
    "                            if 0 <= unit_index < num_units:\n",
    "                                break\n",
    "                            else:\n",
    "                                print() # Retained for separation\n",
    "                                print(\"Input out of range! Please enter a valid unit number.\")\n",
    "                                sys.stdout.flush()\n",
    "                        except ValueError:\n",
    "                            print()\n",
    "                            print(\"Invalid input. Please enter a number.\")\n",
    "                            sys.stdout.flush()\n",
    "                    \n",
    "                    print() # Retained for separation\n",
    "                    # Get new file path\n",
    "                    while True:\n",
    "                        new_path = input(f\"Enter the new file path for RB U{unit_index + 1} (CSV file): \")\n",
    "                        if new_path.lower().endswith(\".csv\"):\n",
    "                            rb_file_paths[unit_index] = new_path\n",
    "                            break\n",
    "                        else:\n",
    "                            print() # Retained for separation\n",
    "                            print(\"Invalid path. It must end with '.csv'.\")\n",
    "                            sys.stdout.flush()\n",
    "\n",
    "                elif path_type == 'limit':\n",
    "                    print() # Retained for separation\n",
    "                    # Get new limit file path\n",
    "                    while True:\n",
    "                        new_path = input(\"Enter the new file path for the limit file (CSV file): \")\n",
    "                        if new_path.lower().endswith(\".csv\"):\n",
    "                            limit_file = new_path\n",
    "                            break\n",
    "                        else:\n",
    "                            print() # Retained for separation\n",
    "                            print(\"Invalid path. It must end with '.csv'.\")\n",
    "                            sys.stdout.flush()\n",
    "                else:\n",
    "                    print(\"Invalid option. Please enter 'NB', 'RB', or 'Limit'.\")\n",
    "                    sys.stdout.flush()\n",
    "                \n",
    "                print() # Retained for separation\n",
    "                \n",
    "                done = input(\"Are you done making changes? (yes/no): \").strip().lower()\n",
    "                print() # Retained for separation\n",
    "                if done == 'yes':\n",
    "                    break\n",
    "\n",
    "    return board_file_paths, rb_file_paths, num_boards, num_units, limit_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58905b34-0eb5-4db4-bf46-ebdae99e6747",
   "metadata": {},
   "source": [
    "### Dataframe cleanup process function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ec1145-0f6d-4027-b22c-ed85a8028bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframes(dataframes):\n",
    "    \"\"\"\n",
    "    Process a list of DataFrames with the following steps:\n",
    "    - Remove rows with NaN values\n",
    "    - Drop the 'Test #' column\n",
    "    - Set 'Description' as the index\n",
    "    - Transpose the DataFrame\n",
    "    - Remove the 'Units' index\n",
    "    - Reset the index\n",
    "    - Convert all data to float\n",
    "\n",
    "    Parameters:\n",
    "    - dataframes: List of DataFrames to process\n",
    "\n",
    "    Returns:\n",
    "    - List of processed DataFrames\n",
    "    \"\"\"\n",
    "    processed_dataframes = []\n",
    "\n",
    "    for df in dataframes:        \n",
    "        df = df.dropna(thresh=df.shape[1] - 1)  # Remove rows with too many NaNs\n",
    "        df = df.set_index('Description')  # Use 'Description' as the index\n",
    "        df = df.drop(df.columns[0], axis=1)  # Drop the first column ('Test #')\n",
    "        df = df.T  # Transpose the DataFrame\n",
    "        df = df.drop(index='Units', errors='ignore')  # Remove 'Units' index if it exists\n",
    "        df = df.reset_index(drop=True)  # Reset the index\n",
    "        df = df.astype(float)  # Convert all values to float\n",
    "        \n",
    "        processed_dataframes.append(df)  # Add the processed DataFrame to the list\n",
    "\n",
    "    return processed_dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d769025-a412-49e8-8ddc-1c00c77b1811",
   "metadata": {},
   "source": [
    "### Mean shift calculation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df7cb8e-efe5-4301-841a-933444d99e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_shift(row):\n",
    "    \"\"\"\n",
    "    Calculate the mean shift percentage based on the provided row data.\n",
    "\n",
    "    This function computes the mean shift percentage using the 'Delta Mean' value \n",
    "    and the specified low and high limits. If either limit is not provided or is \n",
    "    NaN, the function returns NaN. If the 'Delta Mean' is zero, the function returns 0.\n",
    "\n",
    "    Parameters:\n",
    "    - row: A pandas Series representing a row of data, which should contain:\n",
    "        - 'Delta Mean': The delta mean value.\n",
    "        - Column indices 2 and 3 for low and high limits, respectively.\n",
    "\n",
    "    Returns:\n",
    "    - float: The mean shift percentage rounded to five decimal places, or NaN if limits are invalid.\n",
    "    \"\"\"\n",
    "    # Attempt to convert limits to float and check for NaN in one go\n",
    "    low_limit = float(row[2]) if len(row) > 2 else np.nan\n",
    "    high_limit = float(row[3]) if len(row) > 3 else np.nan\n",
    "\n",
    "    # Return np.nan if either limit is NaN\n",
    "    if np.isnan(low_limit) or np.isnan(high_limit):\n",
    "        return np.nan\n",
    "    \n",
    "    # Return 0 if Delta Mean is 0\n",
    "    if row.get('Delta Mean', 0) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Calculate and return the mean shift percentage\n",
    "    return np.round(row['Delta Mean'] / (high_limit - low_limit) * 100, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be20ea-fe67-4d4f-8ec7-a8782e8eaa7d",
   "metadata": {},
   "source": [
    "### Mean shift criteria decision function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adaed8d-3c23-498e-8016-49d42a689ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_shift_crit(row):\n",
    "    \"\"\"\n",
    "    Evaluate the mean shift criteria based on the provided row data.\n",
    "\n",
    "    This function checks the 'Mean Shift' and 'Delta Mean' values against a specified \n",
    "    standard deviation limit. It returns \"Passed\", \"Failed\", or \"For check\" based on \n",
    "    the evaluation criteria.\n",
    "\n",
    "    Parameters:\n",
    "    - row: A pandas Series representing a row of data, which should contain:\n",
    "        - 'Mean Shift': The mean shift value to evaluate.\n",
    "        - 'Delta Mean': The delta mean value.\n",
    "        - Column index 4 for the standard deviation limit.\n",
    "\n",
    "    Returns:\n",
    "    - str: \"Passed\", \"Failed\", or \"For check\" based on the evaluation criteria.\n",
    "    \"\"\"\n",
    "    mean_shf = row['Mean Shift']\n",
    "    d_mean = row['Delta Mean']\n",
    "    sdlot = row[4]\n",
    "\n",
    "    # Check the conditions\n",
    "    if np.isnan(mean_shf):  # Check if mean_shf is NaN\n",
    "        return \"Passed\" if d_mean <= sdlot else \"For check\"\n",
    "    else:\n",
    "        return \"Passed\" if mean_shf <= 5 else \"Failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9ade11-fd7b-4d60-82e7-58b184cb54dc",
   "metadata": {},
   "source": [
    "### Standard deviation ratio calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e1cf7-f7ff-4e46-a6c5-f2eee06d7fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sd_ratio(row):\n",
    "    \"\"\"\n",
    "    Calculate the standard deviation ratio based on the provided row data.\n",
    "\n",
    "    This function computes the ratio of two values from the row. If either of the \n",
    "    values is zero, the function returns 0. Otherwise, it returns the ratio rounded \n",
    "    to six decimal places.\n",
    "\n",
    "    Parameters:\n",
    "    - row: A pandas Series representing a row of data, which should contain:\n",
    "        - Column index 7: The standard deviation for RB at certain unit.\n",
    "        - Column index 9: The standard deviation for certain NB at certain unit.\n",
    "\n",
    "    Returns:\n",
    "    - float: The standard deviation ratio rounded to six decimal places, or 0 if \n",
    "      either value is zero.\n",
    "    \"\"\"\n",
    "    if row[7] == 0:\n",
    "        return 0\n",
    "    elif row[9] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.round(row[9] / row[7], 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3844d3f9-4f55-45bf-be66-63a692b13fb2",
   "metadata": {},
   "source": [
    "### Standard deviation criteria decision function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a1d74c-5c86-4953-85c0-c7a0a3e64994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sd_ratio_crit(row):\n",
    "    \"\"\"\n",
    "    Evaluate the standard deviation ratio criteria based on the provided row data.\n",
    "\n",
    "    This function checks the 'SD Ratio' value against a threshold of 1.5. \n",
    "    It returns \"Passed\" if the ratio is less than or equal to 1.5, \n",
    "    and \"For check\" otherwise.\n",
    "\n",
    "    Parameters:\n",
    "    - row: A pandas Series representing a row of data, which should contain:\n",
    "        - 'SD Ratio': The standard deviation ratio to evaluate.\n",
    "\n",
    "    Returns:\n",
    "    - str: \"Passed\" if the SD Ratio is less than or equal to 1.5, \n",
    "           or \"For check\" if it exceeds 1.5.\n",
    "    \"\"\"\n",
    "    if row[\"SD Ratio\"] <= 1.5:\n",
    "        return \"Passed\"\n",
    "    else:\n",
    "        return \"For check\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2622cdd-f68e-4acf-946d-1e89fa0b408e",
   "metadata": {},
   "source": [
    "### Evaluation status function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8fdedd-8ad5-4957-826d-d8ef3059175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eva_status(row):\n",
    "    \"\"\"\n",
    "    Evaluate the overall status based on mean shift and standard deviation ratio criteria.\n",
    "\n",
    "    This function checks the evaluation status of 'Mean Shift Criteria' and \n",
    "    'SD Ratio Criteria'. It returns \"Passed\" if both criteria are passed, \n",
    "    \"Failed\" if the mean shift criteria has failed, and \"For check\" \n",
    "    for any other combination of statuses.\n",
    "\n",
    "    Parameters:\n",
    "    - row: A pandas Series representing a row of data, which should contain:\n",
    "        - 'Mean Shift Criteria': The evaluation result of the mean shift.\n",
    "        - 'SD Ratio Criteria': The evaluation result of the standard deviation ratio.\n",
    "\n",
    "    Returns:\n",
    "    - str: \"Passed\" if both criteria are passed, \n",
    "           \"Failed\" if the mean shift criteria has failed, \n",
    "           or \"For check\" for any other combination.\n",
    "    \"\"\"\n",
    "    if row['Mean Shift Criteria'] == \"Passed\" and row['SD Ratio Criteria'] == \"Passed\":\n",
    "        return \"Passed\"\n",
    "    elif row['Mean Shift Criteria'] == \"Failed\":\n",
    "        return \"Failed\"\n",
    "    else:\n",
    "        return \"For check\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51888d9a-0326-433b-92d2-1c36d4ca8c6a",
   "metadata": {},
   "source": [
    "### Cp Calculation for RB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b83d060-4191-4521-bc18-70e51ca9acf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cp_rb(row):\n",
    "    \"\"\"\n",
    "    Calculate the Cp and RB value based on the provided row data.\n",
    "\n",
    "    This function computes the Cp and Rb value using the formula:\n",
    "    (row[3] - row[2]) / (6 * row[7]). It checks for specific conditions \n",
    "    before performing the calculation, returning NaN if any of the \n",
    "    required values are zero or missing.\n",
    "\n",
    "    Parameters:\n",
    "    - row: A pandas Series representing a row of data, which should contain:\n",
    "        - row[2]: The lower specification limit.\n",
    "        - row[3]: The upper specification limit.\n",
    "        - row[7]: The standard deviation for RB\n",
    "\n",
    "    Returns:\n",
    "    - float: The calculated Cp and RB value rounded to two decimal places, \n",
    "             or NaN if any of the required values are zero or missing.\n",
    "    \"\"\"\n",
    "    # Check if row[7] is 0\n",
    "    if row[7] == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # Check for empty or \"NA\" values\n",
    "    if row[2] is np.nan or row[3] is np.nan or row[7] is np.nan:\n",
    "        return np.nan\n",
    "    \n",
    "    # Perform the calculation\n",
    "    result = (row[3] - row[2]) / (6 * row[7])\n",
    "    \n",
    "    # Round the result to 2 decimal places\n",
    "    return round(result, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b3c20e-092b-4be7-911d-8b301f071bc4",
   "metadata": {},
   "source": [
    "### Cpk Calculation for RB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7ed9b0-fa68-4fe9-b0b2-dcea6a049a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cpk_rb(row):\n",
    "    \"\"\"\n",
    "    Calculate the CpK and RB value based on the provided row data.\n",
    "\n",
    "    This function computes the CpK value using the available specification limits \n",
    "    and standard deviation. It checks for NaN values and ensures that the standard \n",
    "    deviation is not zero before performing the calculation. The function returns \n",
    "    the CpK value rounded to two decimal places along with a decision message \n",
    "    indicating the capability status.\n",
    "\n",
    "    Parameters:\n",
    "    - row: A pandas Series representing a row of data, which should contain:\n",
    "        - row[2]: The lower specification limit.\n",
    "        - row[3]: The upper specification limit.\n",
    "        - row[6]: The mean for RB at certain unit.\n",
    "        - row[7]: The standard deviation for RB\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing:\n",
    "        - float: The calculated CpK value rounded to two decimal places, \n",
    "                 or NaN if the required values are missing or invalid.\n",
    "        - str: A decision message indicating the capability status (\"Not capable\" \n",
    "               or \"Good capable\").\n",
    "    \"\"\"\n",
    "    # Check for NaN values and if row[7] is 0\n",
    "    if np.isnan(row[2]) and np.isnan(row[3]) or row[7] == 0:\n",
    "        return np.nan, \"N/A\"\n",
    "    \n",
    "    # Calculate cpk based on the available values\n",
    "    if np.isnan(row[2]):\n",
    "        cpk = (row[3] - row[6]) / (3 * row[7])\n",
    "    elif np.isnan(row[3]):\n",
    "        cpk = (row[6] - row[2]) / (3 * row[7])\n",
    "    else:\n",
    "        cpk = min(row[3] - row[6], row[6] - row[2]) / (3 * row[7])\n",
    "\n",
    "    # Round cpk to 2 decimal places\n",
    "    cpk = round(cpk, 2)\n",
    "\n",
    "    # Concise decision statements\n",
    "    if cpk < 1.3:\n",
    "        decision_message = \"Not capable\"\n",
    "    else:\n",
    "        decision_message = \"Good capable\"\n",
    "\n",
    "    return cpk, decision_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7f9808-3e9b-44b6-9593-f0c93f3f65b8",
   "metadata": {},
   "source": [
    "### Cp Calculation for NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef01546-6798-47ff-8ca2-09b592a80a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cp_nb(row):\n",
    "    \"\"\"\n",
    "    Calculate the Cp value based on the provided row data.\n",
    "\n",
    "    This function computes the Cp value using the formula:\n",
    "    (row[3] - row[2]) / (6 * row[12]). It checks for specific conditions \n",
    "    before performing the calculation, returning NaN if any of the \n",
    "    required values are zero or missing.\n",
    "\n",
    "    Parameters:\n",
    "    - row: A pandas Series representing a row of data, which should contain:\n",
    "        - row[2]: The lower specification limit.\n",
    "        - row[3]: The upper specification limit.\n",
    "        - row[12]: The standard deviation for certain NB\n",
    "\n",
    "    Returns:\n",
    "    - float: The calculated Cp value rounded to two decimal places, \n",
    "             or NaN if any of the required values are zero or missing.\n",
    "    \"\"\"\n",
    "    # Check if row[12] is 0\n",
    "    if row[12] == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # Check for empty or \"NA\" values\n",
    "    if np.isnan(row[2]) or np.isnan(row[3]) or np.isnan(row[12]):\n",
    "        return np.nan\n",
    "    \n",
    "    # Perform the calculation\n",
    "    result = (row[3] - row[2]) / (6 * row[12])\n",
    "    \n",
    "    # Round the result to 2 decimal places\n",
    "    return round(result, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51089ff-d8b0-44eb-b0e2-65ae555ed0e7",
   "metadata": {},
   "source": [
    "### Cpk Calculation for NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef2b1f2-b85b-40dc-8dcd-9aad9a9c1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cpk_nb(row):\n",
    "    \"\"\"\n",
    "    Calculate the CpK value based on the provided row data.\n",
    "\n",
    "    This function computes the CpK value using the available specification limits \n",
    "    and standard deviation. It checks for NaN values and ensures that the standard \n",
    "    deviation is not zero before performing the calculation. The function returns \n",
    "    the CpK value rounded to two decimal places along with a decision message \n",
    "    indicating the capability status.\n",
    "\n",
    "    Parameters:\n",
    "    - row: A pandas Series representing a row of data, which should contain:\n",
    "        - row[2]: The lower specification limit.\n",
    "        - row[3]: The upper specification limit.\n",
    "        - row[11]: The mean for certain NB.\n",
    "        - row[12]: The standard deviation for ceratin NB.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing:\n",
    "        - float: The calculated CpK value rounded to two decimal places, \n",
    "                 or NaN if the required values are missing or invalid.\n",
    "        - str: A decision message indicating the capability status (\"Not capable\" \n",
    "               or \"Good capable\").\n",
    "    \"\"\"\n",
    "    # Check for NaN values and if row[12] is 0\n",
    "    if np.isnan(row[2]) and np.isnan(row[3]) or row[12] == 0:\n",
    "        return np.nan, \"N/A\"\n",
    "    \n",
    "    # Calculate cpk based on the available values\n",
    "    if np.isnan(row[2]):\n",
    "        cpk = (row[3] - row[11]) / (3 * row[12])\n",
    "    elif np.isnan(row[3]):\n",
    "        cpk = (row[11] - row[2]) / (3 * row[12])\n",
    "    else:\n",
    "        cpk = min(row[3] - row[11], row[11] - row[2]) / (3 * row[12])\n",
    "\n",
    "    # Round cpk to 2 decimal places\n",
    "    cpk = round(cpk, 2)\n",
    "\n",
    "    # Concise decision statements\n",
    "    if cpk < 1.3:\n",
    "        decision_message = \"Not capable\"\n",
    "    else:\n",
    "        decision_message = \"Good capable\"\n",
    "\n",
    "    return cpk, decision_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d4b673-6b4c-4be5-a3d1-881cdbe0a3ab",
   "metadata": {},
   "source": [
    "### Check value based on number of failure test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b37592-732e-4627-93f3-e0768898e7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_value(col):\n",
    "    \"\"\"\n",
    "    Check the value in the specified column and return a corresponding message.\n",
    "\n",
    "    This function evaluates the value in the fourth element of the provided \n",
    "    column (index 3) which is Failed test all units and returns a message based on its content. \n",
    "\n",
    "    Parameters:\n",
    "    - col: A list or array-like structure where the fourth element (index 3) \n",
    "           is evaluated in this column \"Failed test all units\"\n",
    "\n",
    "    Returns:\n",
    "    - str: A message indicating the status based on the value:\n",
    "        - An empty string if the value is an empty string.\n",
    "        - \"Good to release if no concern\" if the value is 0.\n",
    "        - \"Not acceptable\" for any other value.\n",
    "    \"\"\"\n",
    "    if col[3] == \"\":\n",
    "        return \"\"\n",
    "    elif col[3] == 0:\n",
    "        return \"Good to release if no concern\"\n",
    "    else:\n",
    "        return \"Not acceptable\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bdcf0e-a4c5-47e3-a3a6-aa89148521b7",
   "metadata": {},
   "source": [
    "### Autofit column for generate report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7396f2d-7ed9-43ad-8395-407aff1565e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autosize_columns(worksheet):\n",
    "    \"\"\"\n",
    "    Auto-adjust the width of columns in the given worksheet.\n",
    "\n",
    "    This function iterates through all rows in the specified worksheet and calculates \n",
    "    the maximum length of the content in each column. It then sets the width of each \n",
    "    column based on the calculated maximum lengths, adding a small padding for better \n",
    "    visibility.\n",
    "\n",
    "    Parameters:\n",
    "    - worksheet: An instance of an openpyxl worksheet where the column widths \n",
    "                  need to be adjusted.\n",
    "    \n",
    "    Returns:\n",
    "    - None: This function modifies the worksheet in place and does not return a value.\n",
    "    \"\"\"\n",
    "    column_widths = []\n",
    "\n",
    "    # Iterate through all rows in the worksheet\n",
    "    for row in worksheet.iter_rows(values_only=True):\n",
    "        for i, cell in enumerate(row):\n",
    "            if cell is not None:\n",
    "                cell_length = len(str(cell))  # Get the length of the cell content\n",
    "                if len(column_widths) > i:\n",
    "                    if cell_length > column_widths[i]:\n",
    "                        column_widths[i] = cell_length\n",
    "                else:\n",
    "                    column_widths.append(cell_length)\n",
    "\n",
    "    # Set the width of each column based on the calculated maximum lengths\n",
    "    for i, column_width in enumerate(column_widths, 1):  # Start at 1 for column indexing\n",
    "        worksheet.column_dimensions[get_column_letter(i)].width = column_width + 0.5  # Adding padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86073548-b511-42f6-b225-d384127fd5a2",
   "metadata": {},
   "source": [
    "## Display Banner & Asking Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c3f485-5442-4c54-b0e4-2c1204a2af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the banner to the user\n",
    "display_banner()\n",
    "\n",
    "# Retrieve product information\n",
    "product_info = get_product_information()\n",
    "\n",
    "# Retrieve setup information\n",
    "setup_info = get_setup_information()\n",
    "\n",
    "# Obtain data related to files, number of boards, number of units, and limits\n",
    "nb_file, rb_file, num_boards, num_units, limit = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e7e6e1-dca3-459e-830a-ee1c288cfce2",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab3623e-f882-41af-8472-c86be129ae0b",
   "metadata": {},
   "source": [
    "### Read and Data processing for Limit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6661b6dd-1a6f-4436-a47b-f562d9c6fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "limit = pd.read_csv(limit)\n",
    "\n",
    "# Reset the index of the DataFrame, dropping the old index\n",
    "limit.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert the 'Test #' column to strings and remove '\\t'\n",
    "limit.iloc[:, 0] = limit.iloc[:, 0].astype(str).str.replace(r'\\t', '', regex=True)\n",
    "\n",
    "# Remove rows with too many NaNs\n",
    "limit.dropna(thresh=limit.shape[1] - 3, inplace=True)  \n",
    "\n",
    "# Fill any NaN values with numpy's NaN\n",
    "limit.fillna(np.nan, inplace=True)\n",
    "\n",
    "# Convert the values in the third column to float\n",
    "limit.iloc[:, 2] = limit.iloc[:, 2].astype('float')\n",
    "\n",
    "# Convert the values in the fourth column to float\n",
    "limit.iloc[:, 3] = limit.iloc[:, 3].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e654f6fd-f4b6-4bf5-b899-3e33facc7d7f",
   "metadata": {},
   "source": [
    "### Read RB for all units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6a0a0b-0dc4-468b-ba2a-bdae8c366f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold the DataFrames\n",
    "rb = []\n",
    "\n",
    "# Loop through the unit numbers\n",
    "for i in range(num_units):\n",
    "    # Construct the filename based on the unit number\n",
    "    file_path = rb_file[i]\n",
    "    \n",
    "    # Read the CSV file and append the DataFrame to the list\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)  # Read the CSV file into a DataFrame\n",
    "        rb.append(df)  # Append the DataFrame to the list\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")  # Handle the case where the file is not found\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading {file_path}: {e}\")  # Handle any other exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131f3601-b885-463f-93bb-4438b14493a3",
   "metadata": {},
   "source": [
    "### Read all NB for all units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aefe26-e7a7-4669-95a7-2d73b9c3a179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold the DataFrames for each board\n",
    "nb = []\n",
    "\n",
    "# Loop to get input paths for each board and its units\n",
    "for i in range(num_boards):\n",
    "    board_units = []  # Initialize a list to hold the DataFrames for the current board\n",
    "    \n",
    "    for j in range(num_units):\n",
    "        # Construct the input path based on board and unit numbers\n",
    "        file_path = nb_file[i][j]\n",
    "\n",
    "        # Read the DataFrame from the constructed input path\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)  # Read the CSV file into a DataFrame\n",
    "            board_units.append(df)  # Append the DataFrame for the current unit\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}\")  # Handle the case where the file is not found\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while reading {file_path}: {e}\")  # Handle any other exceptions\n",
    "    \n",
    "    # Append the current board's units to the main list\n",
    "    nb.append(board_units)  # Add the list of DataFrames for the current board to the main list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327230fc-5bec-42bd-a14e-fdb901fdd91c",
   "metadata": {},
   "source": [
    "### Data processing for all NBs and RB for all units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40425591-9be1-49a6-a49a-4a009bc3f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the list of DataFrames for the 'rb' variable\n",
    "rb_mod = process_dataframes(rb)\n",
    "\n",
    "# Initialize an empty list to hold processed DataFrames for each board\n",
    "nb_mod = []\n",
    "\n",
    "# Loop through each board in the 'nb' list\n",
    "for board in nb:\n",
    "    # Process the DataFrames for the current board\n",
    "    processed_units = process_dataframes(board)\n",
    "    \n",
    "    # Append processed DataFrames for each board to the main list\n",
    "    nb_mod.append(processed_units)  # Add the processed units for the current board"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068cdcbe-8032-4263-aa7f-8631dfaf65a2",
   "metadata": {},
   "source": [
    "## Correlation Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a09a7c-48e2-4c03-82f1-93cc2c6bed10",
   "metadata": {},
   "source": [
    "### Calculate mean and standard deviation for RB for all units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b444ef-aaae-4227-b059-cd65ffc166a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to hold the mean and standard deviation DataFrames\n",
    "mean_rb = []\n",
    "std_rb = []\n",
    "\n",
    "# Loop through each modified DataFrame in the 'rb_mod' list\n",
    "for df_mod in rb_mod:\n",
    "    # Calculate the mean for each column and format it to six decimal places\n",
    "    mean = df_mod.mean().apply(lambda x: f'{x:.6f}').astype(float)\n",
    "    \n",
    "    # Calculate the standard deviation for each column (using population standard deviation) and format it to five decimal places\n",
    "    std = df_mod.std(ddof=0).apply(lambda x: f'{x:.5f}').astype(float)\n",
    "    \n",
    "    # Append the mean and standard deviation to their respective lists\n",
    "    mean_rb.append(mean)\n",
    "    std_rb.append(std)\n",
    "\n",
    "# Reset the index of each mean DataFrame to create a clean list of DataFrames\n",
    "mean_rb_clean = [df.reset_index(drop=True) for df in mean_rb]\n",
    "\n",
    "# Reset the index of each standard deviation DataFrame to create a clean list of DataFrames\n",
    "std_rb_clean = [df.reset_index(drop=True) for df in std_rb]\n",
    "\n",
    "# Create a list of column names for the mean DataFrames\n",
    "columns_mean_rb = [f'Mean RB U{i+1}' for i in range(0, num_units)]\n",
    "\n",
    "# Create a list of column names for the standard deviation DataFrames\n",
    "columns_std_rb = [f'SD RB U{i+1}' for i in range(0, num_units)]\n",
    "\n",
    "# Initialize empty DataFrames to hold the real mean and standard deviation values\n",
    "realrbmean = pd.DataFrame()\n",
    "realrbstd = pd.DataFrame()\n",
    "\n",
    "# Loop through each column name and corresponding mean value\n",
    "for col, val in zip(columns_mean_rb, mean_rb_clean):\n",
    "    realrbmean[col] = val  # Assign the mean values to the corresponding column in the DataFrame\n",
    "\n",
    "# Loop through each column name and corresponding standard deviation value\n",
    "for col, val in zip(columns_std_rb, std_rb_clean):\n",
    "    realrbstd[col] = val  # Assign the standard deviation values to the corresponding column in the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf35889-d300-4254-bd5d-8b2d48b109fa",
   "metadata": {},
   "source": [
    "### Calculate mean and standard deviation for all NBs for all units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261e96d7-3506-4703-a4be-5166dae87c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming nb_mod is a list of lists of NumPy arrays instead of DataFrames\n",
    "mean_nb_clean = []  # Initialize the mean list outside the loop\n",
    "std_nb_clean = []   # Initialize the standard deviation list outside the loop\n",
    "\n",
    "# Iterate through each inner list in nb_mod\n",
    "for inner_list in nb_mod:\n",
    "    mean_row = []  # Temporary list to hold means for the current inner list\n",
    "    std_row = []   # Temporary list to hold standard deviations for the current inner list\n",
    "    \n",
    "    # Iterate through each NumPy array in the inner list\n",
    "    for arr_mod in inner_list:\n",
    "        # Calculate mean and standard deviation using NumPy\n",
    "        mean = np.mean(arr_mod, axis=0)  # Calculate mean along the specified axis\n",
    "        std = np.std(arr_mod, axis=0, ddof=0)  # Calculate standard deviation along the specified axis\n",
    "        \n",
    "        # Append results to respective temporary lists\n",
    "        mean_row.append(np.round(mean, 6).tolist())  # Round the mean and convert to list\n",
    "        std_row.append(np.round(std, 5).tolist())    # Round the standard deviation and convert to list\n",
    "    \n",
    "    # Append the temporary lists to the main 2D lists\n",
    "    mean_nb_clean.append(mean_row)  # Add the mean row to the main list\n",
    "    std_nb_clean.append(std_row)     # Add the std row to the main list\n",
    "\n",
    "# mean_nb_clean and std_nb_clean are now 2D lists of means and standard deviations\n",
    "\n",
    "# Create 2D lists to hold column names for means and standard deviations\n",
    "columns_mean_nb = []\n",
    "columns_std_nb = []\n",
    "\n",
    "# Fill the lists with column names for each board\n",
    "for i in range(num_boards + 1):\n",
    "    # Generate mean column names for the current board\n",
    "    mean_columns = [f'Mean NB{i+1} U{j+1}' for j in range(0, num_units)]\n",
    "    \n",
    "    # Generate standard deviation column names for the current board\n",
    "    std_columns = [f'SD NB{i+1} U{j+1}' for j in range(0, num_units)]\n",
    "    \n",
    "    # Append the mean columns for the current board to the list\n",
    "    columns_mean_nb.append(mean_columns)\n",
    "    \n",
    "    # Append the standard deviation columns for the current board to the list\n",
    "    columns_std_nb.append(std_columns)\n",
    "\n",
    "# Create a list to hold the empty DataFrames for means\n",
    "realnbmean = []\n",
    "\n",
    "# Create a list to hold the empty DataFrames for standard deviations\n",
    "realnbstd = []\n",
    "\n",
    "# Loop to create empty DataFrames and append them to the realnbmean list\n",
    "for _ in range(num_boards):\n",
    "    realnbmean.append(pd.DataFrame())  # Append an empty DataFrame for each board\n",
    "\n",
    "# Loop to create empty DataFrames and append them to the realnbstd list\n",
    "for _ in range(num_boards):\n",
    "    realnbstd.append(pd.DataFrame())  # Append an empty DataFrame for each board\n",
    "\n",
    "# Populate the realnbmean DataFrames with mean values\n",
    "for i in range(num_boards):\n",
    "    for col, val in zip(columns_mean_nb[i], mean_nb_clean[i]):\n",
    "        realnbmean[i][col] = val  # Assign mean values to the corresponding columns\n",
    "\n",
    "# Populate the realnbstd DataFrames with standard deviation values\n",
    "for i in range(num_boards):\n",
    "    for col, val in zip(columns_std_nb[i], std_nb_clean[i]):\n",
    "        realnbstd[i][col] = val  # Assign standard deviation values to the corresponding columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d98f48-8784-46a3-9487-8a9518adfb7f",
   "metadata": {},
   "source": [
    "### Create dataframe for limit and RB for all units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a656d89-5f6b-4a7a-8914-59de7a91be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to hold the calculated limits for each unit\n",
    "rb_lim_calc = []  # i = unit\n",
    "\n",
    "# Loop through each unit to calculate limits\n",
    "for i in range(num_units):\n",
    "    # Concatenate the limit DataFrame with the mean and standard deviation for the current unit\n",
    "    temp = pd.concat([limit, realrbmean.iloc[:, i], realrbstd.iloc[:, i]], axis=1)\n",
    "    \n",
    "    # Append the concatenated DataFrame to the rb_lim_calc list\n",
    "    rb_lim_calc.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6978b0c-c3d6-4bd9-b716-52f271214ec7",
   "metadata": {},
   "source": [
    "### Creating and Analyzing DataFrames all NBS for all Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e25e1e-8c80-4d01-87aa-ca263baf48ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D list to hold the concatenated DataFrames for each board and unit\n",
    "rb_nbu = []\n",
    "\n",
    "# Loop through the boards to create the 2D list\n",
    "for i in range(num_boards):\n",
    "    temp_list = []  # Temporary list to hold DataFrames for the current board\n",
    "    for j in range(num_units):\n",
    "        # Concatenate the DataFrames for the current unit, including limits, means, and standard deviations\n",
    "        temp = pd.concat([rb_lim_calc[j], realnbmean[i].iloc[:, j], realnbstd[i].iloc[:, j]], axis=1)\n",
    "        \n",
    "        # Append the concatenated DataFrame to the temporary list\n",
    "        temp_list.append(temp)\n",
    "    \n",
    "    # Append the temporary list of DataFrames for the current board to the main 2D list\n",
    "    rb_nbu.append(temp_list)\n",
    "\n",
    "# Loop through each board\n",
    "for i in range(num_boards):\n",
    "    # Loop through each unit within the current board\n",
    "    for j in range(num_units):\n",
    "        # Calculate the absolute difference between two columns and round it to 6 decimal places\n",
    "        rb_nbu[i][j]['Delta Mean'] = rb_nbu[i][j].apply(lambda row: np.round(abs(row[8] - row[6]), 6), axis=1)\n",
    "        \n",
    "        # Apply the mean_shift function to calculate the mean shift for each row\n",
    "        rb_nbu[i][j]['Mean Shift'] = rb_nbu[i][j].apply(mean_shift, axis=1)\n",
    "        \n",
    "        # Apply the mean_shift_crit function to evaluate the mean shift criteria for each row\n",
    "        rb_nbu[i][j]['Mean Shift Criteria'] = rb_nbu[i][j].apply(mean_shift_crit, axis=1)\n",
    "        \n",
    "        # Apply the sd_ratio function to calculate the standard deviation ratio for each row\n",
    "        rb_nbu[i][j]['SD Ratio'] = rb_nbu[i][j].apply(sd_ratio, axis=1)\n",
    "        \n",
    "        # Apply the sd_ratio_crit function to evaluate the standard deviation ratio criteria for each row\n",
    "        rb_nbu[i][j]['SD Ratio Criteria'] = rb_nbu[i][j].apply(sd_ratio_crit, axis=1)\n",
    "        \n",
    "        # Apply the eva_status function to determine the result for each unit based on the evaluations\n",
    "        rb_nbu[i][j]['Result Unit'] = rb_nbu[i][j].apply(eva_status, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67754809-6fd2-49c8-a3f7-8ada26887acb",
   "metadata": {},
   "source": [
    "### Store all NBs based on Unit Results and Overall NBs Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f602e-5fe0-411e-8c21-1ca8669cc315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to hold the DataFrames for each board\n",
    "nb_results = [pd.DataFrame() for _ in range(num_boards)]\n",
    "\n",
    "# Loop through each board to populate the results\n",
    "for i in range(num_boards):\n",
    "    # Create a new column for each unit's result within the current board\n",
    "    for j in range(num_units):\n",
    "        # Assign the 'Result Unit' data from rb_nbu to the new DataFrame for the current board and unit\n",
    "        nb_results[i][f'Result NB{i+1} U{j+1}'] = rb_nbu[i][j]['Result Unit']\n",
    "\n",
    "    # Check if all results for the board are \"Passed\" and create a new column for the overall result\n",
    "    all_passed = nb_results[i].eq(\"Passed\").all(axis=1)\n",
    "    \n",
    "    # Assign the overall result based on whether all units passed or not\n",
    "    nb_results[i][f\"NB{i+1} Result\"] = all_passed.replace({True: 'Passed', False: 'For check'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1d8734-dc30-467e-8110-dd99c5fb51e4",
   "metadata": {},
   "source": [
    "### Combine Limits with all NBs Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111b48f5-62fc-4572-9cc9-5ee934aa3482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold the concatenated results\n",
    "nbtrueresult = []\n",
    "\n",
    "# Loop through each board to concatenate the limit with the results\n",
    "for i in range(num_boards):\n",
    "    # Concatenate the limit DataFrame/Series with the results DataFrame for the current board\n",
    "    temp = pd.concat([limit, nb_results[i]], axis=1)  # Wrap the arguments in a list\n",
    "    \n",
    "    # Append the concatenated DataFrame to the nbtrueresult list\n",
    "    nbtrueresult.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1829e7-f24c-402c-a568-af7395532737",
   "metadata": {},
   "source": [
    "## Cpk Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa11728d-ba02-49cc-8cc0-ac6926cdce10",
   "metadata": {},
   "source": [
    "### Combine Unit Results for RB and all NBs into a Single DataFrame respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42853311-c890-4124-99c4-5495f589f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all DataFrames in rb_mod for each unit into a single DataFrame, ignoring the index\n",
    "rbdf = pd.concat([rb_mod[i] for i in range(num_units)], ignore_index=True)\n",
    "\n",
    "# Initialize an empty list to hold the concatenated DataFrames for each board\n",
    "nbdf = []\n",
    "\n",
    "# Loop through each board to concatenate the results for all units\n",
    "for i in range(0, num_boards):\n",
    "    # Concatenate all DataFrames in nb_mod for the current board across all units, ignoring the index\n",
    "    temp = pd.concat([nb_mod[i][j] for j in range(num_units)], ignore_index=True)\n",
    "    \n",
    "    # Append the concatenated DataFrame for the current board to the nbdf list\n",
    "    nbdf.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e62e0a-f7c6-4a49-954a-9bcb900070f2",
   "metadata": {},
   "source": [
    "### Calculate Mean for RB and all NBs for DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa76683b-6369-4ee2-abd5-a76e9e959a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the rbdf DataFrame, format it to four decimal places, and convert it to float\n",
    "meanrbdf = rbdf.mean().apply(lambda x: f'{x:.4f}').astype(float).reset_index(drop=True)\n",
    "\n",
    "# Initialize an empty list to hold the mean results for each board\n",
    "meannbdf = []\n",
    "\n",
    "# Loop through each board to calculate the mean of the corresponding DataFrame\n",
    "for i in range(0, num_boards):\n",
    "    # Calculate the mean of the current board's DataFrame, format it to four decimal places, and convert it to float\n",
    "    temp = nbdf[i].mean().apply(lambda x: f'{x:.4f}').astype(float)\n",
    "    \n",
    "    # Append the mean result for the current board to the meannbdf list\n",
    "    meannbdf.append(temp)\n",
    "\n",
    "# Reset the index for each DataFrame in the meannbdf list\n",
    "meannbdf = [df.reset_index(drop=True) for df in meannbdf]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4101a2-a6ef-43e4-b911-b0714f51ec60",
   "metadata": {},
   "source": [
    "### Calculate Standard Deviation for RB and all NBs for DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7bf498-8ac3-42ba-b5e1-aa3af98cd130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of the rbdf DataFrame, format it to four decimal places, and convert it to float\n",
    "stdrbdf = rbdf.std(ddof=0).apply(lambda x: f'{x:.4f}').astype(float).reset_index(drop=True)\n",
    "\n",
    "# Initialize an empty list to hold the standard deviation results for each board\n",
    "stdnbdf = []\n",
    "\n",
    "# Loop through each board to calculate the standard deviation of the corresponding DataFrame\n",
    "for i in range(0, num_boards):\n",
    "    # Calculate the standard deviation of the current board's DataFrame, format it to four decimal places, and convert it to float\n",
    "    temp = nbdf[i].std(ddof=0).apply(lambda x: f'{x:.4f}').astype(float)\n",
    "    \n",
    "    # Append the standard deviation result for the current board to the stdnbdf list\n",
    "    stdnbdf.append(temp)\n",
    "\n",
    "# Reset the index for each DataFrame in the stdnbdf list\n",
    "stdnbdf = [df.reset_index(drop=True) for df in stdnbdf]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8faa0b4-3f5e-4b67-a4fb-01a0c12d2a44",
   "metadata": {},
   "source": [
    "### Combine Mean and Standard Deviation for RB and Each Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef3cc10-5639-4905-b1cc-93c3ab1ad9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the mean and standard deviation DataFrames for rbdf along the columns, ignoring the index\n",
    "meanstdrbdf = pd.concat([meanrbdf, stdrbdf], axis=1, ignore_index=True)\n",
    "\n",
    "# Set the column names for the concatenated DataFrame\n",
    "meanstdrbdf.columns = ['Mean RB', 'SD RB']\n",
    "\n",
    "# Initialize a list to hold the concatenated mean and standard deviation DataFrames for each board\n",
    "meanstdnbdf = [pd.DataFrame() for _ in range(num_boards)]\n",
    "\n",
    "# Loop through each board to concatenate the mean and standard deviation DataFrames\n",
    "for i in range(0, num_boards):\n",
    "    # Concatenate the mean and standard deviation DataFrames for the current board along the columns, ignoring the index\n",
    "    meanstdnbdf[i] = pd.concat([meannbdf[i], stdnbdf[i]], axis=1, ignore_index=True)\n",
    "    \n",
    "    # Set the column names for the concatenated DataFrame of the current board\n",
    "    meanstdnbdf[i].columns = [f'Mean NB{i+1}', f'SD NB{i+1}']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b3382-900d-486c-bc1a-5a608e57acf4",
   "metadata": {},
   "source": [
    "### Calculate Cp and Cpk for RB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324ea55c-3066-4ef2-8d62-f15190f4876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the limit DataFrame with the mean and standard deviation DataFrame for rbdf along the columns\n",
    "rbcpcpk = pd.concat([limit, meanstdrbdf], axis=1)\n",
    "\n",
    "# Apply the calculate_cp_rb function to each row of the concatenated DataFrame to calculate the Cp value for rb\n",
    "rbcpcpk[\"Cp RB\"] = rbcpcpk.apply(calculate_cp_rb, axis=1)\n",
    "\n",
    "# Apply the calculate_cpk_rb function to each row of the concatenated DataFrame to calculate the Cpk values\n",
    "# The result is expanded into two new columns: 'Cpk RB' and 'Cpk RB Result'\n",
    "rbcpcpk[['Cpk RB', 'Cpk RB Result']] = rbcpcpk.apply(calculate_cpk_rb, axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f06e40-c2d0-4c32-9132-93c721f3c8e9",
   "metadata": {},
   "source": [
    "### Calculate Cp and Cpk for Each Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741c7ce6-0560-45b0-9459-d41f1db84adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold the DataFrames for each board's Cp and Cpk results\n",
    "nbcpkresult = []\n",
    "\n",
    "# Loop through each board to concatenate the rbcpcpk DataFrame with the corresponding mean and standard deviation DataFrame\n",
    "for i in range(0, num_boards):\n",
    "    # Concatenate the rbcpcpk DataFrame with the mean and standard deviation DataFrame for the current board\n",
    "    temp = pd.concat([rbcpcpk, meanstdnbdf[i]], axis=1, ignore_index=False)\n",
    "    \n",
    "    # Append the concatenated DataFrame to the nbcpkresult list\n",
    "    nbcpkresult.append(temp)\n",
    "\n",
    "# Loop through each board to calculate the Cp values and add them to the corresponding DataFrame\n",
    "for i in range(0, num_boards):\n",
    "    # Apply the calculate_cp_nb function to each row of the current board's DataFrame to calculate the Cp value\n",
    "    nbcpkresult[i][f\"Cp NB{i+1}\"] = nbcpkresult[i].apply(calculate_cp_nb, axis=1)\n",
    "\n",
    "# Loop through each board to calculate the Cpk values and add them to the corresponding DataFrame\n",
    "for i in range(0, num_boards):\n",
    "    # Apply the calculate_cpk_nb function to each row of the current board's DataFrame to calculate the Cpk values\n",
    "    # The result is expanded into two new columns: 'Cpk NB' and 'Cpk NB Result'\n",
    "    nbcpkresult[i][[f'Cpk NB{i+1}', f'Cpk NB{i+1} Result']] = nbcpkresult[i].apply(calculate_cpk_nb, axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea3463f-5fcd-473f-b567-409077cf2730",
   "metadata": {},
   "source": [
    "## Correlation Result Summary Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70737a44-5b4e-4a78-bfef-03a4f57baba4",
   "metadata": {},
   "source": [
    "### Create a Correlation Table for Test Results for RB and all NBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f795572-9973-4f86-9420-71ad29190bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to hold the correlation table\n",
    "corrtable = pd.DataFrame()\n",
    "\n",
    "# Creating corrtable and adding necessary columns\n",
    "# Add a column for the test card names, formatted with the product info and board index\n",
    "corrtable['Test Card'] = [f\"{product_info['Test Card Name']}_NB{i+1}\" for i in range(num_boards)]\n",
    "\n",
    "# Add a column for the count of passed tests across all units for each board\n",
    "corrtable['Passed test all units'] = [nb_results[i][f\"NB{i+1} Result\"].str.contains('Passed').sum() for i in range(num_boards)]\n",
    "\n",
    "# Add a column for the count of tests marked 'For check' across all units for each board\n",
    "corrtable['For Check test all units'] = [nb_results[i][f\"NB{i+1} Result\"].str.contains('For check').sum() for i in range(num_boards)]\n",
    "\n",
    "# Add a column for the count of failed tests across all units for each board\n",
    "corrtable['Failed test all units'] = [nb_results[i][f\"NB{i+1} Result\"].str.contains('Failed').sum() for i in range(num_boards)]\n",
    "\n",
    "# Adding unit-specific columns for each unit\n",
    "for j in range(num_units):\n",
    "    # Add a column for the count of passed tests for the current unit across all boards\n",
    "    corrtable[f'Passed test U{j+1}'] = [nb_results[i][f\"Result NB{i+1} U{j+1}\"].str.contains('Passed').sum() for i in range(num_boards)]\n",
    "    \n",
    "    # Add a column for the count of tests marked 'For check' for the current unit across all boards\n",
    "    corrtable[f'For Check test U{j+1}'] = [nb_results[i][f\"Result NB{i+1} U{j+1}\"].str.contains('For check').sum() for i in range(num_boards)]\n",
    "    \n",
    "    # Add a column for the count of failed tests for the current unit across all boards\n",
    "    corrtable[f'Failed test U{j+1}'] = [nb_results[i][f\"Result NB{i+1} U{j+1}\"].str.contains('Failed').sum() for i in range(num_boards)]\n",
    "\n",
    "# Add a column for the total number of tests conducted (assuming all boards have the same number of results)\n",
    "corrtable['Total test'] = len(nb_results[0])\n",
    "\n",
    "# Apply a function to check values and add remarks to the DataFrame\n",
    "corrtable['Remarks'] = corrtable.apply(check_value, axis=1)\n",
    "\n",
    "# Set the 'Test Card' column as the index of the DataFrame\n",
    "corrtable.set_index('Test Card', inplace=True)\n",
    "\n",
    "# Transpose the DataFrame to switch rows and columns\n",
    "corrtable = corrtable.T\n",
    "\n",
    "# Optional: Rename the axes for clarity\n",
    "corrtable.rename_axis(\"Test Card\", axis=0, inplace=True)\n",
    "corrtable.rename_axis(\"Index\", axis=1, inplace=True)\n",
    "\n",
    "# Reset the index to convert the index back into a column\n",
    "corrtable.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7a3eb7-b290-4368-b147-db731a589434",
   "metadata": {},
   "source": [
    "### Create DataFrames from Product and Setup Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba18e4e6-b3d6-481d-af94-3f4aba12e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the product_info dictionary, using the index as the first column and 'Details' as the second column\n",
    "df_product_info = pd.DataFrame.from_dict(product_info, orient='index', columns=['Details']).reset_index()\n",
    "\n",
    "# Create a DataFrame from the setup_info dictionary, using the index as the first column and 'Details' as the second column\n",
    "df_setup_info = pd.DataFrame.from_dict(setup_info, orient='index', columns=['Details']).reset_index()\n",
    "\n",
    "# Rename the columns of the product info DataFrame for clarity\n",
    "df_product_info.columns = ['Product Info', 'Details']\n",
    "\n",
    "# Rename the columns of the setup info DataFrame for clarity\n",
    "df_setup_info.columns = ['Setup Info', 'Details']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be069bd9-f92b-46b7-852a-ab3966d7a4d4",
   "metadata": {},
   "source": [
    "## Generate output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b206bf8-d246-4306-924b-06c97b481f81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the output file name for the Excel report, incorporating the test card name and the current date\n",
    "\n",
    "current_date = datetime.now().strftime(\"%d-%m-%Y\")  # Get the current date in YYYY-MM-DD format\n",
    "\n",
    "output_file = f'{product_info[\"Test Card Name\"]}_Correlation_Report_{current_date}.xlsx'\n",
    "\n",
    "# Create an Excel writer object to write multiple DataFrames to an Excel file\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl', mode='w') as writer:\n",
    "    # Write additional DataFrames to specific sheets first\n",
    "    df_product_info.to_excel(writer, sheet_name='Info', index=False)  # Write product info to 'Info' sheet\n",
    "    df_setup_info.to_excel(writer, sheet_name='Info', index=False, startrow=len(df_product_info) + 2, header=True)  # Write setup info below product info\n",
    "    corrtable.to_excel(writer, sheet_name='Correlation Summary', index=False)  # Write correlation summary to its own sheet\n",
    "\n",
    "    # Write the first set of DataFrames (rb_nbu) to separate sheets\n",
    "    for row_index, row in enumerate(rb_nbu):\n",
    "        for col_index, df in enumerate(row):\n",
    "            sheet_name = f'NB{row_index + 1} U{col_index + 1} Corr'  # Create a sheet name based on the row and column index\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)  # Write the DataFrame to the specified sheet\n",
    "            worksheet = writer.sheets[sheet_name]  # Access the worksheet for further formatting\n",
    "\n",
    "    # Apply conditional formatting for specific criteria in the worksheets\n",
    "    for row_index, row in enumerate(rb_nbu):\n",
    "        for col_index, df in enumerate(row):\n",
    "            sheet_name = f'NB{row_index + 1} U{col_index + 1} Corr'\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "            # Apply PatternFill for `Mean Shift Criteria` and `SD Ratio Criteria`\n",
    "            for idx, cell in enumerate(worksheet['M'][1:], start=1):  # Column M: Mean Shift Criteria\n",
    "                value = cell.value\n",
    "                if value == \"Passed\":\n",
    "                    cell.fill = PatternFill(start_color=\"78e08f\", end_color=\"78e08f\", fill_type=\"solid\")\n",
    "                elif value == \"For check\":\n",
    "                    cell.fill = PatternFill(start_color=\"feca57\", end_color=\"feca57\", fill_type=\"solid\")\n",
    "                elif value == \"Failed\":\n",
    "                    cell.fill = PatternFill(start_color=\"ea8685\", end_color=\"ea8685\", fill_type=\"solid\")\n",
    "\n",
    "            for idx, cell in enumerate(worksheet['O'][1:], start=1):  # Column O: SD Ratio Criteria\n",
    "                value = cell.value\n",
    "                if value == \"Passed\":\n",
    "                    cell.fill = PatternFill(start_color=\"78e08f\", end_color=\"78e08f\", fill_type=\"solid\")\n",
    "                elif value == \"For check\":\n",
    "                    cell.fill = PatternFill(start_color=\"feca57\", end_color=\"feca57\", fill_type=\"solid\")\n",
    "                elif value == \"Failed\":\n",
    "                    cell.fill = PatternFill(start_color=\"ea8685\", end_color=\"ea8685\", fill_type=\"solid\")\n",
    "\n",
    "            for idx, cell in enumerate(worksheet['P'][1:], start=1):  # Column P: SD Ratio Criteria\n",
    "                value = cell.value\n",
    "                if value == \"Passed\":\n",
    "                    cell.fill = PatternFill(start_color=\"78e08f\", end_color=\"78e08f\", fill_type=\"solid\")\n",
    "                elif value == \"For check\":\n",
    "                    cell.fill = PatternFill(start_color=\"feca57\", end_color=\"feca57\", fill_type=\"solid\")\n",
    "                elif value == \"Failed\":\n",
    "                    cell.fill = PatternFill(start_color=\"ea8685\", end_color=\"ea8685\", fill_type=\"solid\")\n",
    "\n",
    "    # Write the third set of DataFrames (nbtrueresult) to separate sheets\n",
    "    for i, df in enumerate(nbtrueresult):\n",
    "        sheet_name = f'NB{i + 1} Results'  # Create a sheet name for the results\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)  # Write the DataFrame to the specified sheet\n",
    "        worksheet = writer.sheets[sheet_name]  # Access the worksheet for further formatting\n",
    "\n",
    "        # Apply PatternFill for `Result NB# U#`\n",
    "        for col_index in range(1, len(df.columns)):  # Dynamic column range\n",
    "            if col_index < len(df.columns) - 1:  # Exclude the last \"NB# Result\" column\n",
    "                column_letter = get_column_letter(col_index + 1)\n",
    "                for cell in worksheet[column_letter][1:]:  # Exclude header row\n",
    "                    value = cell.value\n",
    "                    if value == \"Passed\":\n",
    "                        cell.fill = PatternFill(start_color=\"78e08f\", end_color=\"78e08f\", fill_type=\"solid\")\n",
    "                    elif value == \"For check\":\n",
    "                        cell.fill = PatternFill(start_color=\"feca57\", end_color=\"feca57\", fill_type=\"solid\")\n",
    "                    elif value == \"Failed\":\n",
    "                        cell.fill = PatternFill(start_color=\"ea8685\", end_color=\"ea8685\", fill_type=\"solid\")\n",
    "\n",
    "        # Apply PatternFill for `NB# Result` (last column)\n",
    "        result_column_letter = get_column_letter(len(df.columns))  # Last column for \"NB# Result\"\n",
    "        for cell in worksheet[result_column_letter][1:]:  # Exclude header row\n",
    "            value = cell.value\n",
    "            if value == \"Passed\":\n",
    "                cell.fill = PatternFill(start_color=\"78e08f\", end_color=\"78e08f\", fill_type=\"solid\")\n",
    "            elif value == \"For check\":\n",
    "                cell.fill = PatternFill(start_color=\"feca57\", end_color=\"feca57\", fill_type=\"solid\")\n",
    "\n",
    "    # Write the second set of DataFrames (nbcpkresult) to separate sheets\n",
    "    for i, df in enumerate(nbcpkresult):\n",
    "        sheet_name = f'NB{i + 1} CPK'  # Create a sheet name for CPK results\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)  # Write the DataFrame to the specified sheet\n",
    "        worksheet = writer.sheets[sheet_name]  # Access the worksheet for further formatting\n",
    "\n",
    "        # Apply PatternFill for `Cpk RB Result` and `Cpk NB# Result`\n",
    "        for idx, cell in enumerate(worksheet['K'][1:], start=1):  # Column K\n",
    "            value = cell.value\n",
    "            if value == \"Good capable\":\n",
    "                cell.fill = PatternFill(start_color=\"78e08f\", end_color=\"78e08f\", fill_type=\"solid\")\n",
    "            elif value == \"Not capable\":\n",
    "                cell.fill = PatternFill(start_color=\"ea8685\", end_color=\"ea8685\", fill_type=\"solid\")\n",
    "            elif value == \"N/A\":\n",
    "                cell.fill = PatternFill(start_color=\"95afc0\", end_color=\"95afc0\", fill_type=\"solid\")\n",
    "\n",
    "        for idx, cell in enumerate(worksheet['P'][1:], start=1):  # Column P\n",
    "            value = cell.value\n",
    "            if value == \"Good capable\":\n",
    "                cell.fill = PatternFill(start_color=\"78e08f\", end_color=\"78e08f\", fill_type=\"solid\")\n",
    "            elif value == \"Not capable\":\n",
    "                cell.fill = PatternFill(start_color=\"ea8685\", end_color=\"ea8685\", fill_type=\"solid\")\n",
    "            elif value == \"N/A\":\n",
    "                cell.fill = PatternFill(start_color=\"95afc0\", end_color=\"95afc0\", fill_type=\"solid\")\n",
    "\n",
    "    # Access the workbook and the writer's worksheets\n",
    "    workbook = writer.book\n",
    "\n",
    "    # Define a border style for the cells\n",
    "    thin_border = Border(left=Side(style='thin'),\n",
    "                         right=Side(style='thin'),\n",
    "                         top=Side(style='thin'),\n",
    "                         bottom=Side(style='thin'))\n",
    "\n",
    "    fill_color = PatternFill(start_color='82ccdd', end_color='82ccdd', fill_type='solid')\n",
    "    fill_color_info = PatternFill(start_color='74b9ff', end_color='74b9ff', fill_type='solid')\n",
    "    fill_color_corr = PatternFill(None)\n",
    "\n",
    "    # Adjust column widths, add autofilters, and apply formatting\n",
    "    for sheet_name in writer.sheets:\n",
    "        worksheet = workbook[sheet_name]\n",
    "\n",
    "        # Adjust column widths for the current sheet\n",
    "        for column in worksheet.columns:\n",
    "            max_length = max(len(str(cell.value)) for cell in column if cell.value is not None)\n",
    "            adjusted_width = (max_length + 2)\n",
    "            worksheet.column_dimensions[column[0].column_letter].width = adjusted_width\n",
    "\n",
    "            for cell in worksheet[1]:  # Access the first row\n",
    "                cell.fill = fill_color  # Apply the fill to each cell in the first row\n",
    "\n",
    "            for cell in column:\n",
    "                cell.border = thin_border  # Apply border to each cell in the column\n",
    "\n",
    "        # Add autofilter to all sheets except 'Info'\n",
    "        if sheet_name != 'Info':\n",
    "            worksheet.auto_filter.ref = worksheet.dimensions\n",
    "\n",
    "        # Apply borders and formatting to specific sheets\n",
    "        if sheet_name == 'Info':\n",
    "            for cell in worksheet[1]:  # Access the first row\n",
    "                cell.fill = fill_color_info  # Apply the fill to each cell in the first row\n",
    "\n",
    "            for cell in worksheet[8]:  # Access the eighth row\n",
    "                cell.fill = fill_color_info  # Apply the fill to each cell in the eighth row\n",
    "\n",
    "            # Apply borders to the first table (df_product_info)\n",
    "            for row in worksheet.iter_rows(min_row=1, max_row=len(df_product_info) + 1, min_col=1, max_col=len(df_product_info.columns)):\n",
    "                for cell in row:\n",
    "                    cell.border = thin_border  # Apply border to each cell in the first table\n",
    "\n",
    "            # Apply borders to the second table (df_setup_info)\n",
    "            for row in worksheet.iter_rows(min_row=len(df_product_info) + 3, max_row=len(df_product_info) + len(df_setup_info) + 3, min_col=1, max_col=len(df_setup_info.columns)):\n",
    "                for cell in row:\n",
    "                    cell.border = thin_border  # Apply border to each cell in the second table\n",
    "\n",
    "            for cell in worksheet[7]:  # Access the eighth row\n",
    "                cell.border = None  # Remove border from the eighth row\n",
    "\n",
    "        if sheet_name == 'Correlation Summary':\n",
    "            for row in worksheet.iter_rows(min_row=1, max_row=len(corrtable) + 1, min_col=1, max_col=len(corrtable.columns)):\n",
    "                for cell in row:\n",
    "                    cell.border = thin_border  # Apply border to each cell in the correlation summary\n",
    "                    cell.fill = fill_color_corr  # Apply fill color to each cell\n",
    "\n",
    "                    # Align all cells to the left\n",
    "                    cell.alignment = Alignment(horizontal='left')\n",
    "\n",
    "                    # Make the first column bold\n",
    "                    if cell.column == 1:  # Check if it's the first column\n",
    "                        cell.font = Font(bold=True)\n",
    "\n",
    "        # Freeze the first row for all sheets except 'Info' and 'Correlation Summary'\n",
    "        if sheet_name not in ['Info', 'Correlation Summary']:\n",
    "            worksheet.freeze_panes = worksheet['A2']  # Freeze the first row\n",
    "\n",
    "        # Align the first column to the left for all sheets except 'Info' and 'Correlation Summary'\n",
    "        if sheet_name not in ['Info', 'Correlation Summary']:\n",
    "            for cell in worksheet['A'][1:]:  # Access the first column (A), excluding the header\n",
    "                cell.alignment = Alignment(horizontal='left')  # Set alignment to left\n",
    "\n",
    "# Print a message indicating that the DataFrames have been written to the specified output file\n",
    "print()\n",
    "print(f\"Report have been written to '{output_file}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9863be73-bc9e-489e-8084-fe0e4a09a5fe",
   "metadata": {},
   "source": [
    "### Display thank you and countdown timer with exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39a2e6-49d4-4c73-a6ea-cd1acddfe2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the timer duration in seconds\n",
    "timer_duration = 10  # Change this to your desired duration\n",
    "\n",
    "# Call the thank_you function to display a message or perform an action\n",
    "thank_you()\n",
    "\n",
    "# Countdown loop to display the remaining time\n",
    "for remaining in range(timer_duration, 0, -1):\n",
    "    # Print the remaining time, overwriting the same line in the terminal\n",
    "    print(f\"The terminal will close in {remaining} seconds...\", end='\\r')  # Use '\\r' to overwrite the line\n",
    "    time.sleep(1)  # Pause execution for 1 second\n",
    "\n",
    "# Exit the program after the countdown is complete\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac7fe4-7f67-465c-979c-4ac248797169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script Auto_Report_Gen.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
